{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repaso de trabajo con imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset de imagenes\n",
    "\n",
    "* CIFAR-10: clasico de computer vision\n",
    "* consiste de 60,000 imagenes de 32x32 a color (RGB), etiquetadas con un entero que corresponde a 10 clases:\n",
    "    * 0 - avion\n",
    "    * 1 - carro\n",
    "    * 2 - pajaro\n",
    "    * 3 - gato\n",
    "    * 4 - venado\n",
    "    * 5 - perro\n",
    "    * 6 - sapo\n",
    "    * 7 - caballo\n",
    "    * 8 - barco\n",
    "    * 9 - camion\n",
    "    \n",
    "* las imagenes fueron recolectadas y etiquetadas por Krizhevsky, Nair y Hinton de CIFAR (Canadian Institute for Advanced Research)\n",
    "* son un subset de una coleccion mas grande de imagenes a color de 32x32 no etiquetadas\n",
    "    * \"80 million tiny images dataset\"\n",
    "    * CSAIL (Computer Science and Artificial Intelligence Laboratory) de MIT\n",
    "* Ya es considerada demasiado simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargar CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "data_path = \"../data/cifar10/\"\n",
    "\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "               \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "num_classes = 10\n",
    "\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    ax.set_title(class_names[i])\n",
    "    img = next(img for img, label in cifar10 if label == i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El modulo de `datasets` nos da acceso a los datasets de computer vision mas populares:\n",
    "    * MNIST\n",
    "    * FashionMNIST\n",
    "    * CIFAR-100\n",
    "    * SVHN\n",
    "    * Coco\n",
    "    * Omniglot\n",
    "* En todos los casos son retornados como subclases de `torch.utils.data.Dataset`.\n",
    "* Podemos ver que el _method resolution order_ de nuestra instancia `cifar10` lo incluye como su clase base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cifar10).__mro__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La clase Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un Dataset de PyTorch es un objeto que requiere que se implementen dos metodos:\n",
    "    * `__len__`: debe retornar el  numero de items en el dataset\n",
    "    * `__getitem__`: debe retornar el item, consistiendo de una muestra y su etiqueta correspondiente (un entero)\n",
    "    \n",
    "```\n",
    "__len__() -> len(a_dataset)\n",
    "\n",
    "__getitem__(4) -> a_dataset[4]\n",
    "```\n",
    "\n",
    "* En practica cuando un objeto de Python esta equipado con el metodo `__len__`, podemos pasarlo como un argumento a la funcion `len` de python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual forma, como el loader esta equipado con el metodo `__getitem__`, podemos usar el subscript estandar para indexar tuplas y listas para accesar items individuales.\n",
    "\n",
    "En este caso obtenemos una imagen `PIL` con nuestro output deseado, un entero con valor 1, correspondiente a un \"carro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = cifar10[99]\n",
    "img, label, class_names[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La muestra en el dataset `data.CIFAR10` es una instancia de una imagen RGB PIL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como es una imagen de PIL necesitamos una manera de convertirla a un tensor de PyTorch antes de poder hacer algo.\n",
    "* Aqui entra el moduleo `torchvision.transforms`\n",
    "    * funciones (objetos) componibles que pueden pasarse como un argumento a un dataset de `torchvision`\n",
    "    * realizan las transformaciones sobre la data despues de cargarla pero antes de regresarla por `__getitem__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos ver que hay un metodo `ToTensor`\n",
    "    * una vez instanciado puede ser llamado como funcion con la imagen PIL como argumento\n",
    "    * retorna un tensor como output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "img_t = to_tensor(img)\n",
    "img_t.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La imagen se transformo a un tensor 3x32x32, por tanto es una imagen de 3 canales (RGB) y 32x32\n",
    "\n",
    "Podemos pasar el transform directo como un argumento al `dataset.CIFAR10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                                  transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de esto, accesar un elemento del dataset va a retornar un tensor en vez de una imagen PIL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t, _ = tensor_cifar10[99]\n",
    "type(img_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, la forma tiene el canal como primera dimension, mientras que el tipo de escalar es `flaot32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t.size(), img_t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los valores de la imagen PIL original tenian un rango [0,255] (8-bit por canal)\n",
    "* El transform `ToTensor` cambio la data a 32-bit floating point por canal\n",
    "* escalo los valores a [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t.min(), img_t.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos que es la misma imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo es, pero tuvimos que usar `permute` para cambiar el orden de los ejes de CxHxW a HxWxC para pasarle a Matplotlib las dimensiones en el orden que las espera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los transforms son utiles porque podemos encadenar varios usando `transforms.Compose`\n",
    "    * De esta forma podemos manejar la normalizacion y la aumentacion de data de forma transparente y directa en el data loader\n",
    "* Por ejemplo, es buena practica normalizar el dataset para que cada canal tenga $\\mu = 0$ y $\\sigma = 1$\n",
    "    * Si escogemos funciones de activacion que son lineales alrededor de 0 +- 1 (o 2), mantener la data en el mismo rango quiere decir que es mas probable que las neuronas tengan gradientes $\\neq 0$ y por tanto van a aprender antes.\n",
    "    * Asimismo, normalizar cada canal para que tenga la misma distribucion va a asegurar que la informacion del cana puede ser mezclada y actualizada con gradient descent usando el mismo learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como CIFAR-10 es pequenio, podemos manipular todo en memoria. Vamos a apilar todos los tensores en el dataset a lo largo de una dimension extra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)\n",
    "imgs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos calcular la media por canal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.view(3, -1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mismo para la desviacion estandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.view(3, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos numeros podemos inicializar la tranformacion `Normalize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y concatenarlo luego del transform `ToTensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                               (0.2470, 0.2435, 0.2616))\n",
    "                                      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                   (0.2470, 0.2435, 0.2616))\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noten que, despues de esto, plotear una imagen del dataset no nos va a proveer con una buena representacion de la imagen actual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t, _ = transformed_cifar10[99]\n",
    "\n",
    "plt.imshow(img_t.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es porque la normalizacion ha cambiado los niveles de RGB fuera del rango [0.0, 1.0] y tambien las magnitudes generales de los canales.\n",
    "\n",
    "Toda la data sigue ahi, es solo que Matplotlib la representa como negra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El primer paso es tener la data en la forma correcta.\n",
    "* Podriamos hacer una sublcase que solo incluya pajaros y aviones\n",
    "* En vez de eso, la solucion facil es filtrar la data en `cifar10` y remapear las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = [\"airplane\", \"bird\"]\n",
    "\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El uso de Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un modelo lineal entrenado en imagenes tiende a overfit el training set por la configuracion de fully connected layers\n",
    "* Necesita detectar varias posibles traslaciones de objetos en la imagen\n",
    "    * Esto necesita mucho parametros\n",
    "    * lo que causa que se mas facil para el modelo memorizar el training set\n",
    "* No hay independencia de la posicion\n",
    "    * Hace que generalizar sea mas dificil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hay una mejor manera**\n",
    "\n",
    "* Reemplazar las fully connected layers de la NN con una operacion lineal diferente: convolutions\n",
    "* `nn.Linear`: Tomar una vista 1D de una imagen y multiplicarla con una weight matrix de `n_output_features x n_input_features`\n",
    "    * tomar todos los pixeles de la imagen y, por cada canal calcular la suma ponderada de todos los pixeles multiplicados por un set de weights, uno por output feature.\n",
    "* Si queremos reconocer patrones correspondientes a un objeto, necesitamos ver como estan arreglados pixeles cercanos\n",
    "    * Y estariamos menos interesados en en como pixeles separados aparecen en combinacion.\n",
    "* En esencia, no importa si la imagen con el objeto que queremos detectar tiene un arbol, nube, carro en la esquina o no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para trasladar esta intuicion a forma matematica podriamos:\n",
    "    * calcular la suma ponderada de cada pixel con sus vecinos inmediatos, en vez de con todos los otros pixeles.\n",
    "    * Esto seria equivalente a construir weight matrices, una por output feature y ubicacion del output pixel.\n",
    "    * En este caso todos los weights despues de cierta distancia de un pixel central serian cero.\n",
    "* Hay una ultima propiedad deseada: \n",
    "    * queremos que estos patrones localizados tengan un efecto en el output sin importar su ubicacion en la imagen\n",
    "    * esto se llama translation-invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entonces que es una convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una convolution, o mas preciso una convolution discreta (hay una version continua), se define para una imagen de 2D como el producto escalar de un weight matrix, llamado el _kernel_, con todos los vecinos en el input. \n",
    "\n",
    "Consideren un kernel de 3x3 (en deep learning se acostumbra a usar kernels pequenios) como un tensor 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([w00, w01, w02],\n",
    "                      [w10, w11, w12],\n",
    "                      [w20, w21, w22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y una imagen MxN de 1 canal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.tensor([[i00, i01, i02, i03, ..., i0N],\n",
    "                      [i10, i11, i12, i13, ..., i1N],\n",
    "                      [i20, i21, i22, i23, ..., i2N],\n",
    "                      [i30, i31, i32, i33, ..., i3N],\n",
    "                      ...\n",
    "                      [iM0, iM1, iM2, iM3, ..., iMN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular un elemento de la imagen de output (sin bias) como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o11 = i11 * w00 + i12 * w01 + i22 * w02 +\n",
    "      i21 * w10 + i22 * w11 + i23 * w12 +\n",
    "      i31 * w20 + i32 * w21 + i33 * w22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIBUJO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Es decir, estamos \"trasladando\" el kernel en la ubicacion `i11` del input image, y multiplicamos cada peso con el valor de input image en su ubicacion correspondiente.\n",
    "* Por tanto, el output image es creada al trasladar el kernel sobre todas las ubicaciones del input y realizar una suma ponderada.\n",
    "* Para imagenes multi-canal, como nuestras imagenes RGB, el weight matrix seria una matriz 3x3x3,\n",
    "    * i.e. un set de weights por cada canal, contribuyendo en conjunto a los valores del output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notese que el mismo kernel, y por tanto cada weight en el kernel, es reusado a traves de toda la imagen.\n",
    "* Pensando de regreso al Autograd:\n",
    "    * esto quiere decir que el uso de cada weight tiene una historia que incluye la imagen entera.\n",
    "    * por tanto, la derivada del los w.r.t a un convolution weight incluye contribuciones de la imagen entera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, una convolution es equivalente a aplicar multiples operaciones lineales, cuyos pesos son cero casi en todos lados excepto alrededor de pixeles individuales y reciben actualizaciones equivalentes durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En resumen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al cambiar a convolutions optuvimos:\n",
    "* operaciones locales sobre vecinos\n",
    "* translation-invariance\n",
    "* modelos con mucho menos parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El insight clave en el tercer punto es que, con una convolution layer, el numero de parametrso no depende en el numero de pixeles en la imagen, como lo hace en un modelo fully connected.\n",
    "\n",
    "Depende en el convolution kernel (3x3, 5x5, etc) y en cuantos convolution filters (o output channels) decidimos usar en nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions en accion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El modulo `torch.nn` provee convolutions de 1,2 y 3 dimensiones:\n",
    "    * `nn.Conv1d` para series de tiempo\n",
    "    * `nn.Conv2d` para imagenes\n",
    "    * `nn.Conv3d` para videos\n",
    "* Para el dataset de CIFAR-10 vamos a usar `nn.Conv2d`. Como minimo los argumentos necesarios son:\n",
    "    * numero de features. En este caso **channels** porque estamos tratando con imagenes multi-canal, i.e. mas de un valor por pixel.\n",
    "    * numero de output features,\n",
    "    * tamanio del kernel\n",
    "* Por ejemplo, para nuestra primera convolutional layer vamos a tener:\n",
    "    * 3 input features por pixel (los canales de RGB)\n",
    "    * un numero arbitrario de canales en el output, por ejemplo 16\n",
    "    * Mientras mas canales en la imagen de output, mas capacidad del network.\n",
    "    * kernel de 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el kernel_size de 3 es un shortcut para \"3 en cada dimension\"\n",
    "# en este caso 2D, entonces 3x3\n",
    "# de lo contrario pueden pasar una tupla e.i. (3,3)\n",
    "conv = nn.Conv2d(3, 16, kernel_size=3)\n",
    "conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos esperar un `weigt` tensor con el tamanio de la siguiente manera:\n",
    "* Vamos a tener la misma cantidad de kernels, de tamanio `n_input_channels x 3 x 3`, que el numero de output channels\n",
    "* Es decir, esperamos que el `weight` tensor sea de tamanio `n_input_channels x3x3x n_output_channels`, entonces `3x3x3x16`\n",
    "* El bias como siempre es un valor constante que sumamos a cada canale en el output image, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight.size(), conv.bias.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver porque los convolutions son convenientes para aprender de imagenes:\n",
    "* Tenemos modelos mas pequenios,\n",
    "* buscando patrones locales,\n",
    "* cuyos pesos estan optimizados a traves de la imagen entera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un pase de una 2D convolution produce una imagen 2D como output.\n",
    "* Los pixeles son una suma ponderada sobre la imagen de input.\n",
    "* En nuestro caso, los weights del kernel y el bias se inicializan de forma aleatoria\n",
    "    * Por esta razon, la imagen de output no va a hacer sentido.\n",
    "* Como es costumbre, agregamos la dimension 0 (correspondiente al batch) con `unsqueeze`\n",
    "    * Esto se debe a que `nn.Conv2d` espera un tensor de forma `BxCxHxW` como input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze(0).size(), output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver el output despues de un convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El output es mas pequenio\n",
    "    * `torch.Size([1, 16, 30, 30])`\n",
    "* Perdimos un par de pixeles en el proceso\n",
    "* Porque?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Es un efecto secundario de decidir que hacer en la orilla de la imagen.\n",
    "* Aplicar un convolution kernel como una suma ponderada sobre pixeles en un vecindario de 3x3 requiere que hayan vecinos en todas las direcciones.\n",
    "* Si estamos en `i00` solo tenemos pixeles a la derecha y hacia abajo.\n",
    "* Por default, PyTorch se va a saltar los pixeles en la orilla\n",
    "    * por tanto va a producir imagenes que son la mitad del ancho del convolution kernel mas pequenias en cada lado.\n",
    "    * en nuestro caso `3//2 = 1`\n",
    "    * Esto explica porque nos hacen faltas dos pixeles en cada dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PyTorch nos da la posibilidad de hacer **_padding_** sobre la imagen.\n",
    "    * crea pixeles fantasma alrededor del borde que tienen valor de 0 para el convolution.\n",
    "* Por ejemplo, especificar `padding=1` cuando el `kernel_size=3` quiere decir que:\n",
    "    * Ahora `i00` tiene un extra set de vecinos arriba y a su izquierda\n",
    "    * Ahora podemos calcular un output del convolution aun en la esquina de la imagen original\n",
    "    * el resultado es que el output tiene el mismo tamanio que la imagen original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze(0).size(), output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Noten el tamanio del `weight` y el `bias` no cambian se use o no padding.\n",
    "* El `weight` y `bias` son `Parameters` que van a ser aprendidos a traves de backprop\n",
    "    * de la misma forma que sucede para los `weights` y `bias` en `nn.Linear`\n",
    "* Pero podemos jugar con convolutions configurando los weights a mano para ver que pasa\n",
    "    * Primero vamos a hacer cero el `bias`\n",
    "    * Luego vamos a poner los `weights` para que cada pixel en el output obtenga la media de sus vecinos, por cada vecindario 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora miremos el efecto en una imagen de CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El filtro produjo una version borrosa de la imagen.\n",
    "* Cada pixel en el output es un promedio de un vecindario del input\n",
    "    * esto causa que los pixeles del output esten correlacionados y cambien de manera mas suave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos probar algo diferente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0]])\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando la suma ponderada de un pixel arbitrario en posicion `2,2` como hicimos arriba, obtenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o22 = i13 - i11 +\n",
    "      i23 - i21 +\n",
    "      i33 - i31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Esto calcula la diferencia de todos los pixeles a la derecha de `i22`, menos los pixeles a la izquierda de `i22`.\n",
    "* En caso que haya un frontera entre dos regiones adyacentes de intensidad diferente\n",
    "    * `o22` va a tener un valor alto\n",
    "* Si aplicamos el kernel a una region de intensidad uniforme\n",
    "    * `o22` va a ser cero.\n",
    "* Esto se conoce como un edge detection kernel:\n",
    "    * El kernel indica las fronteras verticales entre dos regiones horizontalmente adyacentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El convolution kernel hace mas obvias las fronteras verticales.\n",
    "* Podriamos crear filtros mas elaborados\n",
    "    * detectar fronteras verticales, diagonales\n",
    "    * patrones\n",
    "    * en este caso detectar, quiere decir el el output va a tener una magnitud grande\n",
    "* En DL, dejamos que los kernels sean aprendidos de la data de tal manera que la discriminacion sea la mas efectiva.\n",
    "    * Por ejemplo, en terminos de nuestra loss function aplicada al output y al valor real\n",
    "* Desde este punto de vista, el trabajo de un convolutional NN es estimar el kernel de un banco de filtros en layers sucesivas\n",
    "    * el kernel va a transformar una imagen multi-canal a otra imagen multi-canal\n",
    "    * donde los diferentes canales van a corresponder a diferentes features (un canal para el promedio, otro para fronteras verticales, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth y Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usamos convolutions para lograr locality y translation-invariance\n",
    "* Luego utilizamos kernels pequenios como `3x3` o `5x5`\n",
    "* Pero, como sabemos que todas las estructuras en nuestras imagenes caben en kernels de 3x3 o 5x5?\n",
    "    * No lo sabemos porque no caben\n",
    "* Entonces, como van los NNs a encontrar patrones mas grandes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En los ConvNets usamos stacks varias convolutions sucesivas.\n",
    "* Al mismo tiempo hacemos downsampling de la imagen entre cada convolution layer\n",
    "* El resultado de esto es que:\n",
    "    * el primer conjunto de kernels opera en pequenios vecindarios en features de bajo nivel\n",
    "    * el segundo conjunto de kernels opera sobre vecindarios mas grandes, produciendo features que son composiciones de features previos\n",
    "    * asi sucesivamente\n",
    "* Esto permite al ConvNet ver escenas complejas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![convnet features](../assets/conv_features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El downsampling puede ocurrir de diferentes formas. Por ejemplo, podriamos:\n",
    "    * Promediar todos los pixeles. Un approach que fue al principio bastante comun.\n",
    "    * Tomar el maximo de los pixeles. El que se usa con mas frequencia pero descarta data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Intuitivamente los outputs del convolution layer, tienden a tener alta magnitud donde ciertas features correspondientes al kernel estimado son detectadas.\n",
    "    * Por ejemplo, fronteras verticales\n",
    "* Al mantener el valor mas alto en el downsampled output, nos estamos asegurando que los features que han sido encontrados van a sobrevivir el downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Max-pooling esta en el modulo `nn.MaxPool2d`\n",
    "    * igual que las convolutions hay versiones 1d y 3D\n",
    "* Toma el input del tamanio sobre el cual va a operar la operacion de pooling.\n",
    "* Si queremos downsample nuestra imagen a la mitda, vamos a usar un size de 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img.unsqueeze(0))\n",
    "\n",
    "img.unsqueeze(0).size(), output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST(root=config.mnist_path, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio para el Lunes 28 de Octubre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to PATH_TO_STORE_TRAINSET/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9748480/9912422 [00:10<00:00, 1129784.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PATH_TO_STORE_TRAINSET/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to PATH_TO_STORE_TRAINSET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      "32768it [00:00, 38434.93it/s]                           \n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PATH_TO_STORE_TRAINSET/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to PATH_TO_STORE_TRAINSET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:00<00:14, 115157.19it/s]\u001b[A\n",
      "  4%|▍         | 65536/1648877 [00:00<00:10, 146476.96it/s]\u001b[A\n",
      "  9%|▉         | 147456/1648877 [00:00<00:07, 190224.52it/s]\u001b[A\n",
      " 17%|█▋        | 278528/1648877 [00:00<00:05, 255520.36it/s]\u001b[A\n",
      " 21%|██▏       | 352256/1648877 [00:01<00:04, 309689.85it/s]\u001b[A\n",
      " 34%|███▍      | 565248/1648877 [00:01<00:02, 398543.22it/s]\u001b[A\n",
      " 46%|████▌     | 761856/1648877 [00:01<00:01, 518147.62it/s]\u001b[A\n",
      " 58%|█████▊    | 950272/1648877 [00:01<00:01, 652936.19it/s]\u001b[A\n",
      " 70%|██████▉   | 1146880/1648877 [00:01<00:00, 805486.08it/s]\u001b[A\n",
      " 79%|███████▉  | 1302528/1648877 [00:01<00:00, 931876.96it/s]\u001b[A\n",
      " 88%|████████▊ | 1449984/1648877 [00:01<00:00, 1017026.86it/s]\u001b[A\n",
      "1654784it [00:01, 852124.47it/s]                              \n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PATH_TO_STORE_TRAINSET/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to PATH_TO_STORE_TRAINSET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8192it [00:00, 47794.61it/s]            \n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PATH_TO_STORE_TRAINSET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to PATH_TO_STORE_TESTSET/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9912422 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 16384/9912422 [00:00<01:08, 145481.46it/s]\u001b[A\n",
      "  1%|          | 81920/9912422 [00:00<00:51, 189604.25it/s]\u001b[A\n",
      "  1%|          | 114688/9912422 [00:00<00:46, 211620.54it/s]\u001b[A\n",
      "  2%|▏         | 229376/9912422 [00:00<00:34, 279455.52it/s]\u001b[A\n",
      "  4%|▎         | 352256/9912422 [00:00<00:27, 348107.50it/s]\u001b[A\n",
      "  5%|▍         | 450560/9912422 [00:00<00:22, 419138.14it/s]\u001b[A\n",
      "  6%|▋         | 622592/9912422 [00:01<00:17, 532204.97it/s]\u001b[A\n",
      "  7%|▋         | 712704/9912422 [00:01<00:16, 565457.80it/s]\u001b[A\n",
      "  9%|▉         | 901120/9912422 [00:01<00:12, 715512.50it/s]\u001b[A\n",
      " 10%|█         | 1015808/9912422 [00:01<00:11, 793101.79it/s]\u001b[A\n",
      " 11%|█▏        | 1130496/9912422 [00:01<00:12, 694848.78it/s]\u001b[A\n",
      " 12%|█▏        | 1228800/9912422 [00:01<00:15, 575572.67it/s]\u001b[A\n",
      " 13%|█▎        | 1310720/9912422 [00:02<00:19, 445457.13it/s]\u001b[A\n",
      " 14%|█▍        | 1376256/9912422 [00:02<00:18, 472860.08it/s]\u001b[A\n",
      " 15%|█▍        | 1441792/9912422 [00:02<00:22, 383705.85it/s]\u001b[A\n",
      " 15%|█▌        | 1515520/9912422 [00:02<00:24, 349313.00it/s]\u001b[A\n",
      " 17%|█▋        | 1646592/9912422 [00:02<00:18, 444350.44it/s]\u001b[A\n",
      " 18%|█▊        | 1794048/9912422 [00:02<00:14, 547057.41it/s]\u001b[A\n",
      " 19%|█▉        | 1925120/9912422 [00:03<00:12, 622782.12it/s]\u001b[A\n",
      " 20%|██        | 2015232/9912422 [00:03<00:14, 550232.82it/s]\u001b[A\n",
      " 22%|██▏       | 2138112/9912422 [00:03<00:11, 658846.55it/s]\u001b[A\n",
      " 23%|██▎       | 2310144/9912422 [00:03<00:09, 806218.87it/s]\u001b[A\n",
      " 25%|██▍       | 2441216/9912422 [00:03<00:08, 906391.80it/s]\u001b[A\n",
      " 26%|██▌       | 2572288/9912422 [00:03<00:07, 995774.36it/s]\u001b[A\n",
      " 27%|██▋       | 2695168/9912422 [00:03<00:07, 1018663.26it/s]\u001b[A\n",
      " 29%|██▉       | 2867200/9912422 [00:03<00:06, 1156652.15it/s]\u001b[A\n",
      " 31%|███       | 3055616/9912422 [00:04<00:05, 1266695.12it/s]\u001b[A\n",
      " 32%|███▏      | 3203072/9912422 [00:04<00:05, 1215702.30it/s]\u001b[A\n",
      " 34%|███▍      | 3375104/9912422 [00:04<00:05, 1288869.80it/s]\u001b[A\n",
      " 35%|███▌      | 3514368/9912422 [00:04<00:05, 1132226.59it/s]\u001b[A\n",
      " 38%|███▊      | 3792896/9912422 [00:04<00:04, 1367891.06it/s]\u001b[A\n",
      " 40%|███▉      | 3964928/9912422 [00:05<00:08, 676001.41it/s] \u001b[A\n",
      " 41%|████▏     | 4096000/9912422 [00:05<00:07, 766963.92it/s]\u001b[A\n",
      " 43%|████▎     | 4218880/9912422 [00:05<00:08, 637546.76it/s]\u001b[A\n",
      " 44%|████▎     | 4325376/9912422 [00:05<00:09, 571237.32it/s]\u001b[A\n",
      " 45%|████▍     | 4415488/9912422 [00:05<00:10, 536612.07it/s]\u001b[A\n",
      " 45%|████▌     | 4489216/9912422 [00:08<01:10, 76828.42it/s] \u001b[A\n",
      " 51%|█████     | 5029888/9912422 [00:08<00:44, 108877.77it/s]\u001b[A\n",
      " 52%|█████▏    | 5193728/9912422 [00:09<00:36, 130729.68it/s]\u001b[A\n",
      " 54%|█████▎    | 5316608/9912422 [00:09<00:29, 157904.80it/s]\u001b[A\n",
      " 55%|█████▍    | 5414912/9912422 [00:10<00:30, 147722.05it/s]\u001b[A\n",
      " 55%|█████▌    | 5488640/9912422 [00:10<00:24, 177355.64it/s]\u001b[A\n",
      " 56%|█████▌    | 5570560/9912422 [00:11<00:19, 224784.86it/s]\u001b[A\n",
      " 57%|█████▋    | 5636096/9912422 [00:11<00:17, 246647.90it/s]\u001b[A\n",
      " 57%|█████▋    | 5693440/9912422 [00:11<00:14, 296821.02it/s]\u001b[A\n",
      " 58%|█████▊    | 5750784/9912422 [00:11<00:13, 309749.04it/s]\u001b[A\n",
      " 59%|█████▉    | 5873664/9912422 [00:11<00:10, 397999.33it/s]\u001b[A\n",
      " 60%|█████▉    | 5947392/9912422 [00:11<00:09, 400820.67it/s]\u001b[A\n",
      " 61%|██████    | 6021120/9912422 [00:11<00:08, 457548.28it/s]\u001b[A\n",
      " 61%|██████▏   | 6086656/9912422 [00:12<00:08, 459631.82it/s]\u001b[A\n",
      " 63%|██████▎   | 6258688/9912422 [00:12<00:06, 585070.55it/s]\u001b[A\n",
      " 64%|██████▍   | 6348800/9912422 [00:12<00:09, 368020.33it/s]\u001b[A\n",
      " 65%|██████▍   | 6422528/9912422 [00:12<00:09, 386845.47it/s]\u001b[A\n",
      " 66%|██████▌   | 6529024/9912422 [00:12<00:07, 476692.94it/s]\u001b[A\n",
      " 67%|██████▋   | 6610944/9912422 [00:13<00:06, 504289.59it/s]\u001b[A\n",
      " 68%|██████▊   | 6774784/9912422 [00:13<00:05, 588670.72it/s]\u001b[A\n",
      " 69%|██████▉   | 6856704/9912422 [00:13<00:04, 628586.67it/s]\u001b[A\n",
      " 71%|███████   | 7053312/9912422 [00:13<00:03, 789551.17it/s]\u001b[A\n",
      " 73%|███████▎  | 7217152/9912422 [00:13<00:02, 920058.06it/s]\u001b[A\n",
      " 75%|███████▍  | 7397376/9912422 [00:13<00:02, 1076784.90it/s]\u001b[A\n",
      " 76%|███████▌  | 7544832/9912422 [00:13<00:02, 1059486.35it/s]\u001b[A\n",
      " 79%|███████▊  | 7782400/9912422 [00:13<00:01, 1249260.00it/s]\u001b[A\n",
      " 80%|████████  | 7962624/9912422 [00:14<00:01, 1329201.69it/s]\u001b[A\n",
      " 82%|████████▏ | 8118272/9912422 [00:14<00:01, 1385634.04it/s]\u001b[A\n",
      " 85%|████████▍ | 8404992/9912422 [00:14<00:00, 1521906.78it/s]\u001b[A\n",
      " 87%|████████▋ | 8577024/9912422 [00:14<00:00, 1551581.27it/s]\u001b[A\n",
      " 88%|████████▊ | 8749056/9912422 [00:14<00:00, 1578307.71it/s]\u001b[A\n",
      " 90%|████████▉ | 8921088/9912422 [00:14<00:00, 1330573.11it/s]\u001b[A\n",
      " 91%|█████████▏| 9068544/9912422 [00:14<00:00, 1304108.50it/s]\u001b[A\n",
      " 93%|█████████▎| 9265152/9912422 [00:14<00:00, 1424204.79it/s]\u001b[A\n",
      " 95%|█████████▌| 9420800/9912422 [00:15<00:00, 1222388.83it/s]\u001b[A\n",
      " 97%|█████████▋| 9625600/9912422 [00:15<00:00, 1385955.21it/s]\u001b[A\n",
      " 99%|█████████▊| 9781248/9912422 [00:15<00:00, 1198664.96it/s]\u001b[A\n",
      "9920512it [00:15, 1087571.83it/s]                             \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PATH_TO_STORE_TESTSET/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to PATH_TO_STORE_TESTSET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "32768it [00:00, 103914.24it/s]                           \n",
      "\n",
      "\n",
      "9920512it [00:30, 1129784.64it/s]                             \n",
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PATH_TO_STORE_TESTSET/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to PATH_TO_STORE_TESTSET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 16384/1648877 [00:00<00:12, 131521.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 90112/1648877 [00:00<00:09, 169618.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 245760/1648877 [00:00<00:06, 230535.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 393216/1648877 [00:00<00:04, 307989.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 475136/1648877 [00:00<00:03, 369287.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 655360/1648877 [00:00<00:02, 480212.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 811008/1648877 [00:01<00:01, 598487.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 1081344/1648877 [00:01<00:00, 741309.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 1261568/1648877 [00:01<00:00, 895915.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 1449984/1648877 [00:01<00:00, 1049857.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PATH_TO_STORE_TESTSET/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to PATH_TO_STORE_TESTSET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "8192it [00:00, 43530.75it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PATH_TO_STORE_TESTSET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9920512it [00:26, 1087571.83it/s]\u001b[A\n",
      "\n",
      "1654784it [00:20, 1049857.65it/s]                             \u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 60 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure()\n",
    "num_of_images = 60\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images) #log probabilities\n",
    "loss = criterion(logps, labels) #calculate the NLL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-4.6099e-03, -4.6099e-03, -4.6099e-03,  ..., -4.6099e-03,\n",
      "         -4.6099e-03, -4.6099e-03],\n",
      "        [ 1.8843e-03,  1.8843e-03,  1.8843e-03,  ...,  1.8843e-03,\n",
      "          1.8843e-03,  1.8843e-03],\n",
      "        ...,\n",
      "        [-1.3383e-03, -1.3383e-03, -1.3383e-03,  ..., -1.3383e-03,\n",
      "         -1.3383e-03, -1.3383e-03],\n",
      "        [-2.7226e-04, -2.7226e-04, -2.7226e-04,  ..., -2.7226e-04,\n",
      "         -2.7226e-04, -2.7226e-04],\n",
      "        [-7.8666e-05, -7.8666e-05, -7.8666e-05,  ..., -7.8666e-05,\n",
      "         -7.8666e-05, -7.8666e-05]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.6653974536957263\n",
      "Epoch 1 - Training loss: 0.28235684852324316\n",
      "Epoch 2 - Training loss: 0.2180208152990097\n",
      "Epoch 3 - Training loss: 0.17464067713855935\n",
      "Epoch 4 - Training loss: 0.14643142287379135\n",
      "Epoch 5 - Training loss: 0.12741596350617118\n",
      "Epoch 6 - Training loss: 0.11076535738067332\n",
      "Epoch 7 - Training loss: 0.09974272793798304\n",
      "Epoch 8 - Training loss: 0.08963547982990361\n",
      "Epoch 9 - Training loss: 0.08195329415820428\n",
      "Epoch 10 - Training loss: 0.07469957291698659\n",
      "Epoch 11 - Training loss: 0.06825814801238493\n",
      "Epoch 12 - Training loss: 0.06245342181769134\n",
      "Epoch 13 - Training loss: 0.05863004305294709\n",
      "Epoch 14 - Training loss: 0.054181918402565823\n",
      "\n",
      "Training Time (in minutes) = 2.225169519583384\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 15\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.cpu().data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Digit = 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(valloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "ps = torch.exp(logps)\n",
    "probab = list(ps.numpy()[0])\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.9746\n"
     ]
    }
   ],
   "source": [
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 784)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.numpy()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, './my_mnist_model.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
