{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKWszh9cPm39"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpwRj_pYWWar"
   },
   "source": [
    "1. Experimenten con el numero de neuronas en el modelo al igual que el learning rate.\n",
    "- Que cambios resultan en un output mas lineal del modelo?\n",
    "- Pueden hacer que el modelo haga un overfit obvio de la data?\n",
    "\n",
    "\n",
    "\n",
    "2. Cargen la data de vinos blancos y creen un modelo con el numero apropiado de inputs\n",
    "\n",
    "- Cuanto tarda en entrenar comparado al dataset que hemos estado usando?\n",
    "- Pueden explicar que factores contribuyen a los tiempos de entrenamiento?\n",
    "- Pueden hacer que el loss disminuya?\n",
    "- Intenten graficar la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32gUDqgjWeZT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHZoNG_iXCts"
   },
   "outputs": [],
   "source": [
    "#Clases y Funciones\n",
    "\n",
    "\n",
    "def training_loop(model, n_epochs, optimizer, loss_fn, train_x, val_x, train_y, val_y):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model(train_x) # ya no tenemos que pasar los params\n",
    "        train_loss = loss_fn(train_t_p, train_y)\n",
    "        \n",
    "        with torch.no_grad(): # todos los args requires_grad=False\n",
    "            val_t_p = model(val_x)\n",
    "            val_loss = loss_fn(val_t_p, val_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == 1 or epoch % 1000 == 0:\n",
    "          print(f\"Epoch {epoch}, Training loss {train_loss}, Validation loss {val_loss}\")\n",
    "            \n",
    "class SubclassFunctionalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_linear = nn.Linear(1, 14)\n",
    "        self.output_linear = nn.Linear(14, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        hidden_t = self.hidden_linear(input)\n",
    "        activated_t = torch.tanh(hidden_t)\n",
    "        output_t = self.output_linear(activated_t)\n",
    "\n",
    "        return output_t\n",
    "\n",
    "class SubclassModel(nn.Module):\n",
    "    def __init__(self, num):\n",
    "        super().__init__()\n",
    "        self.hidden_linear = nn.Linear(1, num)\n",
    "        self.hidden_activation = nn.Tanh()\n",
    "        self.output_linear = nn.Linear(num, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden_t = self.hidden_linear(input)\n",
    "        activated_t = self.hidden_activation(hidden_t)\n",
    "        output_t = self.output_linear(activated_t)\n",
    "\n",
    "        return output_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQwF9lS2YZdJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0] # Temperatura en grados celsios\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] # Unidades desconocidas\n",
    "t_c = torch.tensor(t_c).unsqueeze(1) # Agregamos una dimension para tener B x N_inputs\n",
    "t_u = torch.tensor(t_u).unsqueeze(1) # Agregamos una dimension para tener B x N_inputs\n",
    "\n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "train_t_un = 0.1 * train_t_u\n",
    "val_t_un = 0.1 * val_t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WbwqDaVtYoxn",
    "outputId": "479e8513-3601-4fea-d694-81f70ae0ca70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 227.1898651123047, Validation loss 137.93728637695312\n",
      "Epoch 1000, Training loss 104.94120788574219, Validation loss 32.02037811279297\n",
      "Epoch 2000, Training loss 78.16907501220703, Validation loss 15.62597942352295\n",
      "Epoch 3000, Training loss 70.80577087402344, Validation loss 14.734235763549805\n",
      "Epoch 4000, Training loss 66.78810119628906, Validation loss 15.233122825622559\n",
      "Epoch 5000, Training loss 63.281982421875, Validation loss 15.277766227722168\n",
      "output tensor([[10.9715],\n",
      "        [11.5835]], grad_fn=<AddmmBackward>)\n",
      "answer tensor([[ 6.],\n",
      "        [14.]])\n",
      "hidden tensor([[-0.2874],\n",
      "        [ 1.4643],\n",
      "        [-0.1928],\n",
      "        [-1.5301],\n",
      "        [ 0.6822],\n",
      "        [-0.4208],\n",
      "        [ 0.7170],\n",
      "        [ 2.1167],\n",
      "        [-0.6926],\n",
      "        [ 0.2864],\n",
      "        [-0.5172],\n",
      "        [ 1.7126],\n",
      "        [ 2.0038],\n",
      "        [ 0.0080],\n",
      "        [ 0.1402],\n",
      "        [-0.0434],\n",
      "        [ 0.4847],\n",
      "        [ 0.1191],\n",
      "        [ 0.1977],\n",
      "        [-1.5419],\n",
      "        [ 0.8552],\n",
      "        [-1.8799],\n",
      "        [-0.0390],\n",
      "        [ 0.1217],\n",
      "        [ 1.4946],\n",
      "        [ 5.5418],\n",
      "        [-0.1000],\n",
      "        [-2.8971],\n",
      "        [ 1.8890],\n",
      "        [ 0.5052],\n",
      "        [-0.2139],\n",
      "        [ 0.3265],\n",
      "        [-0.6912],\n",
      "        [ 1.4672],\n",
      "        [ 0.4090],\n",
      "        [-0.9675],\n",
      "        [ 1.7046],\n",
      "        [-0.0911],\n",
      "        [ 0.3490],\n",
      "        [ 1.1542],\n",
      "        [ 1.2328],\n",
      "        [ 0.9918],\n",
      "        [-2.4317],\n",
      "        [ 0.3578],\n",
      "        [-0.1270],\n",
      "        [ 1.5774],\n",
      "        [ 1.7792],\n",
      "        [-0.6987],\n",
      "        [-0.8572],\n",
      "        [ 0.5941]])\n"
     ]
    }
   ],
   "source": [
    "############################################Intento 1####################################################\n",
    "subclass_model = SubclassModel(50)\n",
    "\n",
    "optimizer = optim.SGD(subclass_model.parameters(), lr=1e-5)\n",
    "training_loop(\n",
    "    n_epochs=5000,\n",
    "    optimizer=optimizer,\n",
    "    model=subclass_model,\n",
    "    loss_fn=nn.MSELoss(), # Ya no estamos usando nuestra loss function hecha a mano\n",
    "    train_x = train_t_un,\n",
    "    val_x = val_t_un,\n",
    "    train_y = train_t_c,\n",
    "    val_y = val_t_c)\n",
    "\n",
    "print('output', subclass_model(val_t_un))\n",
    "print('answer', val_t_c)\n",
    "print('hidden', subclass_model.hidden_linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MU-U03hwbHXq",
    "outputId": "3cae3a8f-7661-431f-d692-fe9a67507ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 203.8484649658203, Validation loss 116.9561538696289\n",
      "Epoch 1000, Training loss 55.82001495361328, Validation loss 15.818521499633789\n",
      "Epoch 2000, Training loss 40.11280822753906, Validation loss 14.70352840423584\n",
      "Epoch 3000, Training loss 29.22624969482422, Validation loss 13.790350914001465\n",
      "Epoch 4000, Training loss 21.88345718383789, Validation loss 13.021085739135742\n",
      "Epoch 5000, Training loss 17.05974578857422, Validation loss 12.361532211303711\n",
      "output tensor([[10.9360],\n",
      "        [13.4020]], grad_fn=<AddmmBackward>)\n",
      "answer tensor([[ 6.],\n",
      "        [14.]])\n",
      "hidden tensor([[-2.5529e-02],\n",
      "        [-1.6419e-01],\n",
      "        [-1.0247e-02],\n",
      "        [-2.0078e-02],\n",
      "        [ 4.1668e-03],\n",
      "        [-5.1272e-03],\n",
      "        [ 7.0656e-05],\n",
      "        [ 8.9424e-02],\n",
      "        [ 4.4134e-03],\n",
      "        [-2.0467e-01],\n",
      "        [ 6.1034e-02],\n",
      "        [-6.3968e-03],\n",
      "        [-1.3632e-05],\n",
      "        [ 3.8927e-02],\n",
      "        [ 2.4013e-03],\n",
      "        [-7.8301e-05],\n",
      "        [-7.3741e-01],\n",
      "        [ 3.4150e-03],\n",
      "        [-6.1423e-03],\n",
      "        [ 1.2299e-01],\n",
      "        [-4.3693e-04],\n",
      "        [-5.8860e-01],\n",
      "        [ 4.2670e-01],\n",
      "        [-9.9633e-02],\n",
      "        [ 3.8431e-03],\n",
      "        [ 7.5825e-02],\n",
      "        [ 1.5341e-02],\n",
      "        [-2.3691e-04],\n",
      "        [-2.7671e-03],\n",
      "        [-1.1266e+00],\n",
      "        [ 4.5870e-06],\n",
      "        [-9.9349e-02],\n",
      "        [ 1.4565e-02],\n",
      "        [-2.7933e-02],\n",
      "        [-6.2423e-02],\n",
      "        [-5.8167e-01],\n",
      "        [ 1.0458e-03],\n",
      "        [-1.4724e-02],\n",
      "        [-8.2130e-03],\n",
      "        [ 1.0867e-01],\n",
      "        [ 2.4279e-01],\n",
      "        [ 1.1501e-03],\n",
      "        [ 8.5449e-03],\n",
      "        [-2.4201e-03],\n",
      "        [-1.6297e-02],\n",
      "        [ 3.3569e-04],\n",
      "        [-2.6225e-03],\n",
      "        [ 1.0245e+00],\n",
      "        [-8.3438e-02],\n",
      "        [-6.3116e-02],\n",
      "        [ 3.1212e-02],\n",
      "        [-7.4255e-03],\n",
      "        [-4.6735e-03],\n",
      "        [-2.3752e-03],\n",
      "        [-3.7533e-04],\n",
      "        [-5.0736e-01],\n",
      "        [ 2.7025e-03],\n",
      "        [ 4.9532e-04],\n",
      "        [ 6.7866e-03],\n",
      "        [-1.2388e-01],\n",
      "        [ 7.2334e-01],\n",
      "        [-1.6083e-02],\n",
      "        [ 1.1068e-03],\n",
      "        [-8.9149e-02],\n",
      "        [ 6.3266e-02],\n",
      "        [-1.4853e-02],\n",
      "        [-2.5185e-02],\n",
      "        [-6.6776e-03],\n",
      "        [ 2.7593e-03],\n",
      "        [-6.0938e-04],\n",
      "        [-5.3293e-01],\n",
      "        [-2.2628e-01],\n",
      "        [ 9.6345e-04],\n",
      "        [-3.9217e-02],\n",
      "        [ 2.4838e-03],\n",
      "        [ 5.5665e-03],\n",
      "        [-9.0213e-04],\n",
      "        [-2.7116e-01],\n",
      "        [-7.0370e-03],\n",
      "        [ 8.5902e-03],\n",
      "        [-6.2354e-04],\n",
      "        [ 2.7708e-03],\n",
      "        [-4.6693e-04],\n",
      "        [ 3.6913e-04],\n",
      "        [ 2.6934e-03],\n",
      "        [-8.3802e-03],\n",
      "        [ 2.2355e-01],\n",
      "        [ 1.0162e-01],\n",
      "        [-6.3500e-01],\n",
      "        [-6.8856e-01],\n",
      "        [-1.4751e-02],\n",
      "        [-4.5790e-03],\n",
      "        [-1.7218e-03],\n",
      "        [ 9.6261e-03],\n",
      "        [-1.6175e-03],\n",
      "        [-2.4422e-03],\n",
      "        [ 4.0864e-03],\n",
      "        [-1.7243e-01],\n",
      "        [-8.6296e-04],\n",
      "        [ 3.4484e-01],\n",
      "        [-3.5037e-01],\n",
      "        [ 3.6081e-01],\n",
      "        [ 1.3371e-02],\n",
      "        [ 1.6374e-02],\n",
      "        [-4.4579e-04],\n",
      "        [-1.0808e+00],\n",
      "        [-4.8598e-04],\n",
      "        [ 8.6240e-02],\n",
      "        [-5.4484e-03],\n",
      "        [ 2.3582e-03],\n",
      "        [ 1.6253e-02],\n",
      "        [ 2.2941e-02],\n",
      "        [ 7.2976e-01],\n",
      "        [-5.6391e-04],\n",
      "        [ 1.0456e-02],\n",
      "        [ 1.1998e-02],\n",
      "        [-7.8997e-04],\n",
      "        [-1.9905e-01],\n",
      "        [ 1.4285e-02],\n",
      "        [ 1.2272e-02],\n",
      "        [ 7.9650e-03],\n",
      "        [ 1.1531e-02],\n",
      "        [-4.9865e-01],\n",
      "        [ 9.1831e-04],\n",
      "        [-4.5888e-05],\n",
      "        [ 3.4999e-01],\n",
      "        [ 8.2006e-01],\n",
      "        [-6.5359e-04],\n",
      "        [-7.0027e-03],\n",
      "        [-8.5478e-03],\n",
      "        [-5.8345e-02],\n",
      "        [ 1.9480e-04],\n",
      "        [-6.8481e-03],\n",
      "        [ 1.6147e-01],\n",
      "        [-3.5924e-02],\n",
      "        [ 5.7020e-03],\n",
      "        [-6.0053e-04],\n",
      "        [-2.0709e-03],\n",
      "        [-1.1136e-02],\n",
      "        [ 4.5520e-04],\n",
      "        [ 1.7327e-02],\n",
      "        [ 7.3502e-02],\n",
      "        [ 2.3004e-01],\n",
      "        [ 8.3230e-02],\n",
      "        [ 1.3338e-01],\n",
      "        [-8.4316e-03],\n",
      "        [-4.9712e-02],\n",
      "        [-9.3002e-03],\n",
      "        [-1.7733e-03],\n",
      "        [ 6.4715e-02],\n",
      "        [ 4.1352e-01],\n",
      "        [ 2.5801e-02],\n",
      "        [ 3.7687e-02],\n",
      "        [-1.5248e-02],\n",
      "        [-3.6085e-03],\n",
      "        [ 9.6254e-04],\n",
      "        [ 1.5675e-03],\n",
      "        [-6.6908e-03],\n",
      "        [ 5.2919e-01],\n",
      "        [-7.6797e-03],\n",
      "        [ 1.2134e-03],\n",
      "        [ 4.5238e-03],\n",
      "        [-6.8659e-01],\n",
      "        [ 1.0359e-02],\n",
      "        [ 9.4863e-03],\n",
      "        [-8.0769e-04],\n",
      "        [-3.2097e-02],\n",
      "        [-4.0875e-03],\n",
      "        [ 4.6800e-03],\n",
      "        [-3.2003e-02],\n",
      "        [ 8.6936e-02],\n",
      "        [-1.1025e-01],\n",
      "        [ 2.2217e-01],\n",
      "        [ 5.4368e-01],\n",
      "        [-9.6763e-03],\n",
      "        [-3.9358e-03],\n",
      "        [ 5.5927e-01],\n",
      "        [-3.5172e-03],\n",
      "        [ 1.1143e-03],\n",
      "        [-7.1800e-02],\n",
      "        [-5.3663e-04],\n",
      "        [-8.7566e-03],\n",
      "        [ 5.4320e-03],\n",
      "        [-8.7964e-04],\n",
      "        [-4.3197e-03],\n",
      "        [-2.4674e-03],\n",
      "        [-7.0036e-04],\n",
      "        [-2.4782e-02],\n",
      "        [-8.1253e-01],\n",
      "        [ 3.7439e-03],\n",
      "        [-3.0138e-01],\n",
      "        [ 5.0843e-01],\n",
      "        [-6.7256e-02],\n",
      "        [-1.4126e-02],\n",
      "        [ 4.7436e-01],\n",
      "        [ 6.4028e-02],\n",
      "        [ 6.8109e-04],\n",
      "        [ 3.9004e-03],\n",
      "        [ 1.0169e-03],\n",
      "        [ 1.3348e-01],\n",
      "        [ 1.2753e-03],\n",
      "        [-5.3478e-04],\n",
      "        [-3.4694e-02],\n",
      "        [ 1.0683e-01],\n",
      "        [ 3.5135e-03],\n",
      "        [-1.5768e-03],\n",
      "        [-5.7711e-03],\n",
      "        [-2.2796e-03],\n",
      "        [-1.0777e-01],\n",
      "        [-1.4906e-02],\n",
      "        [ 9.1718e-01],\n",
      "        [-5.0294e-03],\n",
      "        [-1.0374e+00],\n",
      "        [ 4.6727e-03],\n",
      "        [ 4.7810e-03],\n",
      "        [-2.8480e-01],\n",
      "        [ 7.1739e-01],\n",
      "        [ 2.2509e-03],\n",
      "        [-3.8702e-03],\n",
      "        [-5.1615e-04],\n",
      "        [-7.3617e-03],\n",
      "        [ 1.0384e-02],\n",
      "        [ 6.2278e-05],\n",
      "        [ 4.8217e-02],\n",
      "        [ 6.5867e-03],\n",
      "        [-1.9707e-01],\n",
      "        [ 7.8762e-04],\n",
      "        [ 5.5870e-03],\n",
      "        [-1.2656e-03],\n",
      "        [ 5.3656e-03],\n",
      "        [-5.0351e-02],\n",
      "        [-3.0059e-01],\n",
      "        [-6.6899e-03],\n",
      "        [ 1.1283e-04],\n",
      "        [ 5.0877e-04],\n",
      "        [ 2.1561e-02],\n",
      "        [-4.4258e-01],\n",
      "        [-7.0763e-01],\n",
      "        [-8.2299e-04],\n",
      "        [ 6.6289e-02],\n",
      "        [ 2.3191e-02],\n",
      "        [-3.1535e-03],\n",
      "        [-6.6315e-01],\n",
      "        [-3.8801e-03],\n",
      "        [-2.1978e-02],\n",
      "        [ 4.7915e-02],\n",
      "        [-1.0745e-02],\n",
      "        [-1.8335e-03],\n",
      "        [ 3.9102e-03],\n",
      "        [-2.0020e-02],\n",
      "        [ 1.4093e-03],\n",
      "        [-6.2900e-03],\n",
      "        [ 2.3220e-03],\n",
      "        [ 2.4494e-02],\n",
      "        [ 2.1692e-02],\n",
      "        [-1.0084e-01],\n",
      "        [ 9.9380e-02],\n",
      "        [ 4.5620e-04],\n",
      "        [-2.4942e-03],\n",
      "        [-6.3991e-01],\n",
      "        [-3.8401e-02],\n",
      "        [-2.4760e-02],\n",
      "        [-6.7218e-03],\n",
      "        [-2.5165e-01],\n",
      "        [ 1.6960e-03],\n",
      "        [ 1.9521e-02],\n",
      "        [-3.6082e-02],\n",
      "        [-5.2113e-01],\n",
      "        [-1.5143e-04],\n",
      "        [-9.1583e-03],\n",
      "        [-8.4966e-03],\n",
      "        [-1.0873e-03],\n",
      "        [-5.7549e-01],\n",
      "        [-4.5227e-02],\n",
      "        [-1.2423e-02],\n",
      "        [-2.4723e-01],\n",
      "        [-2.4426e-03],\n",
      "        [ 6.1548e-03],\n",
      "        [-5.3272e-03],\n",
      "        [-8.3459e-04],\n",
      "        [-1.7612e-03],\n",
      "        [-1.6710e-03],\n",
      "        [-8.8395e-03],\n",
      "        [ 4.2777e-03],\n",
      "        [-2.2667e-04],\n",
      "        [-1.7101e-03],\n",
      "        [-8.8541e-04],\n",
      "        [-8.4568e-03],\n",
      "        [ 2.9301e-03],\n",
      "        [-5.0336e-02],\n",
      "        [ 8.0843e-03],\n",
      "        [ 1.4783e-02],\n",
      "        [-1.1991e-02],\n",
      "        [ 1.0307e-01],\n",
      "        [ 2.9660e-02],\n",
      "        [ 7.3897e-03],\n",
      "        [ 1.1377e-03],\n",
      "        [ 6.6357e-02],\n",
      "        [ 6.5705e-07],\n",
      "        [ 1.3981e-01],\n",
      "        [ 2.2520e-03],\n",
      "        [ 6.2076e-04],\n",
      "        [-1.6009e-03],\n",
      "        [ 9.9347e-02],\n",
      "        [-1.9020e-01],\n",
      "        [ 2.1262e-02],\n",
      "        [ 2.4074e-02],\n",
      "        [-3.6666e-01],\n",
      "        [ 4.8751e-01],\n",
      "        [-3.2052e-02],\n",
      "        [-2.5590e-01],\n",
      "        [ 2.6149e-02],\n",
      "        [-7.5959e-01],\n",
      "        [ 9.8006e-02],\n",
      "        [ 2.9782e-03],\n",
      "        [ 5.4296e-01],\n",
      "        [ 5.6233e-03],\n",
      "        [ 8.2995e-02],\n",
      "        [-5.7365e-05],\n",
      "        [-3.4364e-01],\n",
      "        [ 8.4852e-04],\n",
      "        [-1.9243e-03],\n",
      "        [ 2.9844e-02],\n",
      "        [ 3.6950e-03],\n",
      "        [-1.9112e-02],\n",
      "        [-2.1202e-03],\n",
      "        [-8.7799e-01],\n",
      "        [ 1.7614e-03],\n",
      "        [ 7.0975e-01],\n",
      "        [ 4.4290e-03],\n",
      "        [ 9.0898e-02],\n",
      "        [-1.2234e-01],\n",
      "        [ 1.8976e-03],\n",
      "        [-1.2194e-03],\n",
      "        [ 4.4138e-03],\n",
      "        [ 2.5375e-03],\n",
      "        [ 6.5707e-01],\n",
      "        [ 4.5479e-01],\n",
      "        [ 8.1890e-04],\n",
      "        [ 4.1197e-01],\n",
      "        [ 8.7737e-03],\n",
      "        [-2.9063e-04],\n",
      "        [-2.0394e-02],\n",
      "        [ 1.0424e-02],\n",
      "        [ 1.0081e-02],\n",
      "        [ 1.5433e-01],\n",
      "        [-1.8701e-03],\n",
      "        [-1.9763e-03],\n",
      "        [ 3.9500e-03],\n",
      "        [ 5.4080e-02],\n",
      "        [ 3.7631e-03],\n",
      "        [-2.3841e-01],\n",
      "        [-3.3885e-03],\n",
      "        [-8.6467e-03],\n",
      "        [ 4.7030e-01],\n",
      "        [-1.3518e-01],\n",
      "        [ 4.4314e-01],\n",
      "        [-3.7626e-02],\n",
      "        [ 4.4010e-01],\n",
      "        [-7.6514e-01],\n",
      "        [-4.6320e-03],\n",
      "        [-6.3626e-02],\n",
      "        [-1.0001e-01],\n",
      "        [-8.3426e-03],\n",
      "        [-7.7308e-03],\n",
      "        [-3.9480e-04],\n",
      "        [-2.2099e-01],\n",
      "        [ 4.0082e-04],\n",
      "        [ 1.6714e-02],\n",
      "        [ 4.3456e-02],\n",
      "        [ 1.3419e-02],\n",
      "        [ 7.5606e-02],\n",
      "        [ 1.5923e-01],\n",
      "        [ 3.1804e-01],\n",
      "        [ 1.4068e-03],\n",
      "        [ 5.9950e-03],\n",
      "        [ 6.1836e-06],\n",
      "        [-1.4873e-02],\n",
      "        [ 1.5460e-01],\n",
      "        [ 7.7814e-02],\n",
      "        [-4.2295e-03],\n",
      "        [ 3.1094e-02],\n",
      "        [-3.2818e-02],\n",
      "        [-2.2004e-02],\n",
      "        [-1.0936e-02],\n",
      "        [ 9.3609e-03],\n",
      "        [ 7.2169e-02],\n",
      "        [ 2.6395e-02],\n",
      "        [-8.1175e-01],\n",
      "        [ 9.4400e-03],\n",
      "        [ 8.0945e-02],\n",
      "        [ 5.0766e-03],\n",
      "        [ 1.3151e-02],\n",
      "        [-7.9788e-01],\n",
      "        [-3.5048e-04],\n",
      "        [ 1.3106e-02],\n",
      "        [-4.0593e-01],\n",
      "        [-6.0803e-04],\n",
      "        [ 7.5431e-03],\n",
      "        [-3.0407e-02],\n",
      "        [ 5.3481e-04],\n",
      "        [-1.9499e-04],\n",
      "        [ 2.1561e-01],\n",
      "        [-1.7850e-01],\n",
      "        [ 3.2301e-03],\n",
      "        [-1.5926e-03],\n",
      "        [-5.7487e-01],\n",
      "        [ 1.9362e-03],\n",
      "        [ 1.2598e-02],\n",
      "        [-7.4890e-03],\n",
      "        [ 5.8904e-04],\n",
      "        [ 2.5313e-03],\n",
      "        [ 6.0471e-01],\n",
      "        [ 1.9223e-01],\n",
      "        [ 1.7875e-04],\n",
      "        [ 1.8386e-02],\n",
      "        [ 3.9922e-01],\n",
      "        [-1.1870e-01],\n",
      "        [ 9.3231e-03],\n",
      "        [ 3.1935e-03],\n",
      "        [ 6.9458e-03],\n",
      "        [-2.6908e-01],\n",
      "        [-1.2846e-02],\n",
      "        [ 1.0146e-02],\n",
      "        [-7.6937e-05],\n",
      "        [-1.8145e-02],\n",
      "        [ 1.5844e-02],\n",
      "        [-1.5340e-03],\n",
      "        [-4.8907e-01],\n",
      "        [-3.8071e-02],\n",
      "        [ 1.0783e-02],\n",
      "        [ 1.7520e-02],\n",
      "        [-1.8873e-03],\n",
      "        [-4.8775e-04],\n",
      "        [-2.4234e-03],\n",
      "        [ 5.1221e-03],\n",
      "        [ 8.0523e-03],\n",
      "        [-1.0093e-02],\n",
      "        [-5.2003e-03],\n",
      "        [-5.5089e-03],\n",
      "        [-6.3847e-03],\n",
      "        [-1.7242e-01],\n",
      "        [ 8.2603e-03],\n",
      "        [-2.6675e-03],\n",
      "        [ 1.8102e-01],\n",
      "        [-2.3335e-02],\n",
      "        [-5.8685e-02],\n",
      "        [-3.5992e-02],\n",
      "        [ 1.9893e-01],\n",
      "        [ 5.7686e-03],\n",
      "        [ 1.3452e-03],\n",
      "        [-1.0142e-02],\n",
      "        [-2.4087e-01],\n",
      "        [-6.4154e-03],\n",
      "        [-4.7215e-01],\n",
      "        [-1.8148e-05],\n",
      "        [ 5.5244e-01],\n",
      "        [ 4.0637e-04],\n",
      "        [-2.1675e-01],\n",
      "        [-1.0591e-01],\n",
      "        [-1.9817e-01],\n",
      "        [ 1.9267e-01],\n",
      "        [ 4.9281e-01],\n",
      "        [ 3.9913e-02],\n",
      "        [-2.5544e-03],\n",
      "        [ 3.6796e-04],\n",
      "        [ 1.2735e-03],\n",
      "        [-1.2574e-02],\n",
      "        [-4.6145e-02],\n",
      "        [-7.1332e-03],\n",
      "        [ 7.9138e-02],\n",
      "        [ 2.3470e-03],\n",
      "        [-2.6385e-04],\n",
      "        [-3.1140e-01],\n",
      "        [ 2.1109e-02],\n",
      "        [-6.6986e-02],\n",
      "        [ 1.2765e-04],\n",
      "        [ 8.0172e-03],\n",
      "        [-3.8412e-01],\n",
      "        [-1.2436e-02],\n",
      "        [-5.9779e-01],\n",
      "        [-8.5245e-04],\n",
      "        [ 3.2001e-02],\n",
      "        [-6.9156e-03],\n",
      "        [-8.9401e-02],\n",
      "        [-6.9420e-02],\n",
      "        [-2.5710e-01],\n",
      "        [-1.2404e-03],\n",
      "        [ 3.9694e-02],\n",
      "        [-3.8687e-02],\n",
      "        [ 2.5426e-03],\n",
      "        [-2.3850e-03],\n",
      "        [ 8.0873e-04],\n",
      "        [-8.4767e-03],\n",
      "        [-1.4936e-01],\n",
      "        [-1.1389e-01],\n",
      "        [-7.6168e-03],\n",
      "        [ 5.0056e-02],\n",
      "        [ 1.0533e-03],\n",
      "        [ 3.6666e-02],\n",
      "        [-2.3725e-01],\n",
      "        [ 2.6950e-02],\n",
      "        [-5.1580e-01],\n",
      "        [ 7.2957e-01],\n",
      "        [-1.6983e-01],\n",
      "        [-4.2704e-04],\n",
      "        [-7.5893e-02],\n",
      "        [ 3.4927e-03],\n",
      "        [-2.1746e-03],\n",
      "        [ 2.9677e-03],\n",
      "        [-5.3127e-04],\n",
      "        [ 1.3481e-01],\n",
      "        [-5.0564e-01],\n",
      "        [ 7.5949e-02],\n",
      "        [-5.4975e-03],\n",
      "        [-1.0245e-01],\n",
      "        [ 3.0813e-01],\n",
      "        [ 3.9521e-03],\n",
      "        [-1.8290e-03],\n",
      "        [ 8.4395e-03],\n",
      "        [-5.8546e-03],\n",
      "        [-1.4558e-02],\n",
      "        [ 1.9031e-01],\n",
      "        [ 4.2741e-04],\n",
      "        [ 1.3624e-04],\n",
      "        [ 1.7861e-02],\n",
      "        [ 2.2491e-02],\n",
      "        [ 1.1670e-03],\n",
      "        [ 7.5038e-04],\n",
      "        [-3.2583e-03],\n",
      "        [-3.0435e-03],\n",
      "        [-8.9497e-02],\n",
      "        [-1.7452e-02],\n",
      "        [ 8.4905e-04],\n",
      "        [-3.7904e-04],\n",
      "        [ 1.0229e-01],\n",
      "        [-6.1109e-03],\n",
      "        [-3.8637e-03],\n",
      "        [-4.8895e-02],\n",
      "        [-1.5688e-03],\n",
      "        [ 2.8680e-01],\n",
      "        [-2.9525e-03],\n",
      "        [-7.2819e-04],\n",
      "        [ 1.8627e-02],\n",
      "        [-4.1227e-02],\n",
      "        [-2.2171e-01],\n",
      "        [-2.5363e-01],\n",
      "        [-2.6774e-03],\n",
      "        [ 5.6400e-04],\n",
      "        [ 1.0651e-02],\n",
      "        [ 5.5098e-02],\n",
      "        [ 2.7158e-03],\n",
      "        [ 3.9518e-03],\n",
      "        [-9.2140e-03],\n",
      "        [ 5.7847e-03],\n",
      "        [ 1.4534e-03],\n",
      "        [-7.9827e-03],\n",
      "        [-2.3986e-01],\n",
      "        [ 4.9913e-04],\n",
      "        [-9.0310e-03],\n",
      "        [ 3.3599e-03],\n",
      "        [-1.1731e-02],\n",
      "        [-1.4747e-02],\n",
      "        [-6.8638e-01],\n",
      "        [-4.3049e-01],\n",
      "        [ 4.8569e-02],\n",
      "        [ 8.8356e-02],\n",
      "        [ 6.7306e-03],\n",
      "        [-3.7061e-02],\n",
      "        [-7.9881e-03],\n",
      "        [ 5.8634e-02],\n",
      "        [ 2.5801e-02],\n",
      "        [-8.2667e-05],\n",
      "        [-7.9735e-02],\n",
      "        [-8.7478e-02],\n",
      "        [ 8.9466e-03],\n",
      "        [-5.7735e-04],\n",
      "        [-5.8776e-01],\n",
      "        [ 2.5787e-04],\n",
      "        [ 1.6239e-02],\n",
      "        [-1.5700e-02],\n",
      "        [ 1.8238e-05],\n",
      "        [ 1.9677e-03],\n",
      "        [-2.0187e-03],\n",
      "        [-6.7923e-03],\n",
      "        [-1.1018e-01],\n",
      "        [ 2.4092e-02],\n",
      "        [ 2.2495e-02],\n",
      "        [-1.6807e-01],\n",
      "        [-5.7010e-01],\n",
      "        [-2.1183e-02],\n",
      "        [-8.5661e-02],\n",
      "        [-7.6324e-03],\n",
      "        [-4.0170e-04],\n",
      "        [-6.1428e-03],\n",
      "        [ 7.3315e-01],\n",
      "        [ 3.2152e-03],\n",
      "        [-3.3972e-04],\n",
      "        [-1.0215e-02],\n",
      "        [-3.0730e-01],\n",
      "        [-7.1210e-03],\n",
      "        [-1.9640e-04],\n",
      "        [-1.6987e-03],\n",
      "        [ 6.7577e-03],\n",
      "        [ 3.0859e-04],\n",
      "        [ 1.7917e-02],\n",
      "        [-1.0212e-04],\n",
      "        [ 1.6395e-03],\n",
      "        [-2.6264e-03],\n",
      "        [-1.0136e-01],\n",
      "        [-1.9296e-03],\n",
      "        [ 6.6634e-03],\n",
      "        [-4.3541e-02],\n",
      "        [ 1.2325e-02],\n",
      "        [ 5.3062e-04],\n",
      "        [ 3.7763e-02],\n",
      "        [ 2.7534e-03],\n",
      "        [-2.0138e-01],\n",
      "        [ 9.7024e-02],\n",
      "        [ 1.3423e-02],\n",
      "        [-4.9533e-01],\n",
      "        [ 9.0939e-02],\n",
      "        [-1.7305e-03],\n",
      "        [-2.4805e-02],\n",
      "        [ 7.8257e-01],\n",
      "        [-4.6250e-03],\n",
      "        [ 8.1979e-04],\n",
      "        [ 2.3027e-04],\n",
      "        [-3.7171e-02],\n",
      "        [-1.2705e-01],\n",
      "        [-1.8575e-01],\n",
      "        [-7.0413e-01],\n",
      "        [-2.4826e-03],\n",
      "        [-3.5026e-01],\n",
      "        [-6.7210e-04],\n",
      "        [-1.6050e-02],\n",
      "        [-3.1103e-01],\n",
      "        [-6.9873e-02],\n",
      "        [-2.6481e-03],\n",
      "        [ 3.3982e-02],\n",
      "        [-2.3336e-02],\n",
      "        [-5.4837e-04],\n",
      "        [ 1.1444e-02],\n",
      "        [-1.5236e-02],\n",
      "        [ 1.6660e-01],\n",
      "        [ 5.1130e-02],\n",
      "        [ 1.4654e-03],\n",
      "        [-2.4559e-02],\n",
      "        [-2.6937e-01],\n",
      "        [-3.4556e-04],\n",
      "        [-1.3178e-02],\n",
      "        [ 2.1838e-01],\n",
      "        [-8.3348e-05],\n",
      "        [ 2.7221e-01],\n",
      "        [-1.0271e-04],\n",
      "        [-5.7875e-03],\n",
      "        [-8.7235e-01],\n",
      "        [ 1.7312e-02],\n",
      "        [ 2.6399e-03],\n",
      "        [ 7.6946e-03],\n",
      "        [ 2.5676e-01],\n",
      "        [-9.5451e-05],\n",
      "        [-4.0962e-03],\n",
      "        [-8.1337e-03],\n",
      "        [-5.1594e-02],\n",
      "        [ 1.9334e-02],\n",
      "        [-6.8243e-05],\n",
      "        [ 9.1975e-04],\n",
      "        [-5.3010e-03],\n",
      "        [-2.0781e-03],\n",
      "        [-4.5382e-03],\n",
      "        [ 4.7286e-04],\n",
      "        [-2.0254e-02],\n",
      "        [-1.8566e-02],\n",
      "        [-9.2829e-02],\n",
      "        [-9.1271e-04],\n",
      "        [-8.3003e-04],\n",
      "        [ 1.7305e-03],\n",
      "        [-2.1499e-02],\n",
      "        [ 1.1490e-02],\n",
      "        [-1.5740e-01],\n",
      "        [-9.6862e-03],\n",
      "        [ 1.1759e-02],\n",
      "        [ 1.7013e-01],\n",
      "        [-3.2894e-01],\n",
      "        [ 9.1623e-03],\n",
      "        [-4.4589e-02],\n",
      "        [ 8.8266e-03],\n",
      "        [-5.3657e-03],\n",
      "        [ 8.7173e-01],\n",
      "        [ 5.6607e-03],\n",
      "        [-1.3396e-04],\n",
      "        [-7.8061e-03],\n",
      "        [ 1.6961e-02],\n",
      "        [-3.8449e-01],\n",
      "        [ 7.0943e-02],\n",
      "        [-1.2215e-01],\n",
      "        [-1.0551e-03],\n",
      "        [-3.0959e-02],\n",
      "        [ 5.4170e-02],\n",
      "        [ 8.3353e-01],\n",
      "        [-2.6396e-03],\n",
      "        [-1.8060e-03],\n",
      "        [-1.0140e-02],\n",
      "        [ 6.4725e-03],\n",
      "        [-3.5774e-02],\n",
      "        [ 1.0866e-01],\n",
      "        [-1.5409e-02],\n",
      "        [ 8.8020e-03],\n",
      "        [-8.8836e-03],\n",
      "        [-3.1174e-02],\n",
      "        [ 1.0062e-01],\n",
      "        [ 1.7497e-01],\n",
      "        [-2.4127e-02],\n",
      "        [ 7.4138e-01],\n",
      "        [ 7.3309e-01],\n",
      "        [ 8.7011e-01],\n",
      "        [-6.6960e-01],\n",
      "        [-7.8035e-03],\n",
      "        [ 2.1892e-02],\n",
      "        [ 2.0508e-01],\n",
      "        [ 1.0043e-03],\n",
      "        [ 5.9613e-03],\n",
      "        [ 2.6864e-03],\n",
      "        [ 6.1991e-04],\n",
      "        [ 2.3156e-03],\n",
      "        [-7.3238e-04],\n",
      "        [ 9.9956e-01],\n",
      "        [-2.9936e-02],\n",
      "        [-3.2713e-03],\n",
      "        [-2.1239e-01],\n",
      "        [ 9.0603e-04],\n",
      "        [ 5.5333e-03],\n",
      "        [-3.8961e-01],\n",
      "        [-3.8584e-01],\n",
      "        [ 7.8345e-01],\n",
      "        [-5.6722e-02],\n",
      "        [-7.4088e-04],\n",
      "        [ 9.2927e-03],\n",
      "        [-8.3964e-03],\n",
      "        [-5.8412e-03],\n",
      "        [-1.2912e-02],\n",
      "        [ 7.6432e-02],\n",
      "        [-3.8287e-03],\n",
      "        [ 1.9413e-02],\n",
      "        [ 2.7702e-03],\n",
      "        [-9.7511e-03],\n",
      "        [-3.4044e-02],\n",
      "        [-5.8093e-03],\n",
      "        [-6.5232e-03],\n",
      "        [ 1.3822e-01],\n",
      "        [ 4.0549e-04],\n",
      "        [ 4.4588e-04],\n",
      "        [-4.5498e-02],\n",
      "        [-8.8942e-03],\n",
      "        [ 3.9809e-02],\n",
      "        [ 1.6091e-03],\n",
      "        [ 2.1102e-02],\n",
      "        [ 9.3498e-02],\n",
      "        [ 4.3686e-02],\n",
      "        [ 2.2545e-01],\n",
      "        [-3.5970e-03],\n",
      "        [ 1.4787e-02],\n",
      "        [ 2.4917e-02],\n",
      "        [-5.1843e-01],\n",
      "        [ 2.1232e-03],\n",
      "        [-6.9153e-02],\n",
      "        [ 1.3550e-04],\n",
      "        [ 4.0345e-03],\n",
      "        [-1.0727e-01],\n",
      "        [-3.3685e-01],\n",
      "        [-1.2590e-03],\n",
      "        [-3.1307e-03],\n",
      "        [ 2.6935e-01],\n",
      "        [ 4.6510e-04],\n",
      "        [-1.2926e-02],\n",
      "        [ 1.1393e-03],\n",
      "        [-5.1396e-04],\n",
      "        [-1.1646e-02],\n",
      "        [-4.3793e-01],\n",
      "        [ 4.0992e-03],\n",
      "        [-4.4506e-04],\n",
      "        [-6.0995e-01],\n",
      "        [ 9.1186e-03],\n",
      "        [-8.6377e-02],\n",
      "        [-5.9481e-02],\n",
      "        [ 3.4051e-01],\n",
      "        [ 6.3783e-03],\n",
      "        [ 2.2726e-03],\n",
      "        [-2.6827e-02],\n",
      "        [-2.9783e-03],\n",
      "        [-4.9771e-04],\n",
      "        [-9.5803e-03],\n",
      "        [ 4.6771e-07],\n",
      "        [-2.5149e-03],\n",
      "        [-3.6051e-02],\n",
      "        [-3.8849e-02],\n",
      "        [ 4.3224e-03],\n",
      "        [-2.5966e-01],\n",
      "        [ 2.0356e-02],\n",
      "        [-1.7500e-01],\n",
      "        [-2.2612e-01],\n",
      "        [-3.1751e-01],\n",
      "        [-4.9217e-04],\n",
      "        [ 7.7129e-03],\n",
      "        [ 1.2035e-01],\n",
      "        [-3.0137e-01],\n",
      "        [-1.5752e-02],\n",
      "        [-2.7581e-01],\n",
      "        [ 7.4729e-01],\n",
      "        [-5.6874e-02],\n",
      "        [-2.2754e-01],\n",
      "        [-2.1240e-02],\n",
      "        [ 3.0623e-02],\n",
      "        [-6.5290e-02],\n",
      "        [-2.2750e-02],\n",
      "        [ 4.7125e-03],\n",
      "        [ 2.2257e-01],\n",
      "        [ 8.7823e-03],\n",
      "        [ 7.5572e-04],\n",
      "        [-5.8280e-01],\n",
      "        [ 2.3606e-03],\n",
      "        [-6.2931e-03],\n",
      "        [-3.3715e-04],\n",
      "        [ 6.6189e-03],\n",
      "        [-1.7048e-01],\n",
      "        [-2.8348e-02],\n",
      "        [ 6.3560e-03],\n",
      "        [-8.0291e-03],\n",
      "        [-2.6333e-04],\n",
      "        [-4.7388e-03],\n",
      "        [-4.9369e-02],\n",
      "        [ 2.1014e-04],\n",
      "        [-1.0843e-02],\n",
      "        [-4.9485e-03],\n",
      "        [ 5.7948e-02],\n",
      "        [-6.7730e-04],\n",
      "        [ 1.9017e-03],\n",
      "        [ 2.1254e-02],\n",
      "        [ 4.3787e-01],\n",
      "        [-1.3636e-01],\n",
      "        [ 3.7956e-02],\n",
      "        [-1.3210e-02],\n",
      "        [ 3.2865e-03],\n",
      "        [-1.0347e-01],\n",
      "        [-6.2173e-03],\n",
      "        [-7.2764e-02],\n",
      "        [ 9.7895e-04],\n",
      "        [ 4.9350e-03],\n",
      "        [ 1.0579e-03],\n",
      "        [ 4.1680e-03],\n",
      "        [ 4.5916e-03],\n",
      "        [ 7.1576e-04],\n",
      "        [-1.8059e-02],\n",
      "        [ 2.9687e-04],\n",
      "        [-9.9062e-03],\n",
      "        [-2.3750e-02],\n",
      "        [ 7.0465e-01],\n",
      "        [ 6.5252e-02],\n",
      "        [-6.1887e-01],\n",
      "        [-4.9842e-03],\n",
      "        [-3.6749e-03],\n",
      "        [ 9.8780e-04],\n",
      "        [-1.7626e-02],\n",
      "        [ 1.0943e-02],\n",
      "        [-2.3649e-03],\n",
      "        [ 5.7294e-03],\n",
      "        [-1.5971e-02],\n",
      "        [-8.2792e-03],\n",
      "        [-4.2829e-01],\n",
      "        [-4.1708e-01],\n",
      "        [ 8.8171e-02],\n",
      "        [-1.3669e-02],\n",
      "        [-3.4345e-01],\n",
      "        [-3.6687e-03],\n",
      "        [-7.7884e-01],\n",
      "        [ 7.7983e-03],\n",
      "        [ 7.2662e-04],\n",
      "        [-1.0237e-01],\n",
      "        [-5.5551e-03],\n",
      "        [-3.3029e-03],\n",
      "        [-2.5476e-03],\n",
      "        [-5.4382e-04],\n",
      "        [-7.4341e-02],\n",
      "        [-1.7137e-02],\n",
      "        [-6.3671e-03],\n",
      "        [-2.0766e-02],\n",
      "        [-8.4962e-01],\n",
      "        [ 1.1956e-03],\n",
      "        [ 1.6734e-03],\n",
      "        [-2.0009e-03],\n",
      "        [-2.0488e-02],\n",
      "        [-5.7015e-01],\n",
      "        [-2.0048e-03],\n",
      "        [ 3.4097e-03],\n",
      "        [ 9.2423e-03],\n",
      "        [ 1.1423e-03],\n",
      "        [ 1.7260e-01],\n",
      "        [ 1.0620e-01],\n",
      "        [-2.3989e-02],\n",
      "        [ 5.7415e-03],\n",
      "        [ 1.7767e-02],\n",
      "        [-5.6038e-02],\n",
      "        [ 1.2719e-03],\n",
      "        [ 9.5253e-02],\n",
      "        [-6.7775e-04],\n",
      "        [ 2.0106e-03],\n",
      "        [ 8.9820e-03],\n",
      "        [ 2.8893e-01],\n",
      "        [ 3.7647e-04],\n",
      "        [-2.0945e-02],\n",
      "        [ 2.9295e-02],\n",
      "        [ 5.6336e-02],\n",
      "        [-2.8517e-01],\n",
      "        [ 7.1216e-03],\n",
      "        [ 2.1650e-02],\n",
      "        [-3.6012e-03],\n",
      "        [-1.2934e-01],\n",
      "        [ 1.0760e-02],\n",
      "        [ 8.5301e-03],\n",
      "        [-1.0470e-03],\n",
      "        [-1.1306e-03],\n",
      "        [-1.6491e-02],\n",
      "        [ 4.3047e-03],\n",
      "        [ 2.5332e-02],\n",
      "        [-4.8260e-03],\n",
      "        [ 3.5491e-03],\n",
      "        [-9.5615e-04],\n",
      "        [-1.0542e-01],\n",
      "        [ 7.0911e-04],\n",
      "        [-6.4558e-03],\n",
      "        [ 4.5841e-02],\n",
      "        [-5.5385e-02],\n",
      "        [-4.4707e-03],\n",
      "        [-1.8986e-02],\n",
      "        [-1.7490e-01],\n",
      "        [-1.0506e-02],\n",
      "        [ 5.4644e-02],\n",
      "        [-7.9137e-04],\n",
      "        [-5.1878e-01],\n",
      "        [ 9.1131e-03],\n",
      "        [-5.5736e-01],\n",
      "        [ 1.2450e-02],\n",
      "        [-3.5740e-03],\n",
      "        [ 3.3266e-04],\n",
      "        [ 2.3253e-03],\n",
      "        [-5.1227e-02],\n",
      "        [-2.0144e-01],\n",
      "        [-4.1875e-03],\n",
      "        [ 3.7169e-03],\n",
      "        [ 6.8469e-01],\n",
      "        [ 2.5841e-01],\n",
      "        [-7.7894e-04],\n",
      "        [-2.2662e-03],\n",
      "        [ 1.0433e-03],\n",
      "        [ 1.1350e-02],\n",
      "        [-1.3473e-01],\n",
      "        [ 1.2753e-02],\n",
      "        [-4.6055e-03],\n",
      "        [ 3.3764e-03],\n",
      "        [-1.0316e-01],\n",
      "        [-5.7700e-04],\n",
      "        [ 4.7556e-03],\n",
      "        [ 5.4138e-01],\n",
      "        [ 9.8915e-01],\n",
      "        [ 1.0959e-03],\n",
      "        [ 3.0357e-02],\n",
      "        [ 1.6444e-04],\n",
      "        [ 6.9747e-01],\n",
      "        [-1.4436e-04],\n",
      "        [ 3.1373e-02],\n",
      "        [ 1.9369e-03],\n",
      "        [-1.5180e-02],\n",
      "        [ 1.8696e-01],\n",
      "        [ 1.0372e-01],\n",
      "        [-8.1282e-01],\n",
      "        [-5.1467e-02],\n",
      "        [-2.2752e-03],\n",
      "        [ 2.3913e-03],\n",
      "        [-2.7365e-02],\n",
      "        [ 6.6882e-03],\n",
      "        [-3.0129e-01],\n",
      "        [-8.1080e-04],\n",
      "        [-1.4903e-03],\n",
      "        [-5.4060e-01],\n",
      "        [-2.8393e-02],\n",
      "        [-5.6227e-03],\n",
      "        [-6.9717e-02],\n",
      "        [ 2.2684e-02],\n",
      "        [-4.7364e-03],\n",
      "        [ 8.8865e-03],\n",
      "        [-1.7175e-03],\n",
      "        [ 1.0745e-01],\n",
      "        [ 1.9156e-02],\n",
      "        [ 2.2863e-04],\n",
      "        [-5.2993e-03],\n",
      "        [-4.3262e-04],\n",
      "        [ 5.9973e-03],\n",
      "        [ 1.1430e-04],\n",
      "        [ 8.7192e-01]])\n"
     ]
    }
   ],
   "source": [
    "############################################Intento 2####################################################\n",
    "subclass_model = SubclassModel(1000)\n",
    "\n",
    "optimizer = optim.SGD(subclass_model.parameters(), lr=1e-5)\n",
    "training_loop(\n",
    "    n_epochs=5000,\n",
    "    optimizer=optimizer,\n",
    "    model=subclass_model,\n",
    "    loss_fn=nn.MSELoss(), # Ya no estamos usando nuestra loss function hecha a mano\n",
    "    train_x = train_t_un,\n",
    "    val_x = val_t_un,\n",
    "    train_y = train_t_c,\n",
    "    val_y = val_t_c)\n",
    "\n",
    "print('output', subclass_model(val_t_un))\n",
    "print('answer', val_t_c)\n",
    "print('hidden', subclass_model.hidden_linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PSGziEw4c0jd",
    "outputId": "be2336ff-9acb-4743-a608-4801ad78e2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 198.5008544921875, Validation loss 111.4076919555664\n",
      "Epoch 1000, Training loss 11.112096786499023, Validation loss 16.463834762573242\n",
      "Epoch 2000, Training loss 4.429706573486328, Validation loss 5.2980875968933105\n",
      "Epoch 3000, Training loss 2.343747615814209, Validation loss 3.381012201309204\n",
      "Epoch 4000, Training loss 1.7161966562271118, Validation loss 3.2322564125061035\n",
      "Epoch 5000, Training loss 1.5252286195755005, Validation loss 3.340428590774536\n",
      "output tensor([[ 7.1029],\n",
      "        [11.2233]], grad_fn=<AddmmBackward>)\n",
      "answer tensor([[ 6.],\n",
      "        [14.]])\n",
      "hidden tensor([[ 2.0810e-01],\n",
      "        [ 2.2465e-01],\n",
      "        [-1.0361e+00],\n",
      "        [-2.7257e-01],\n",
      "        [ 2.7322e-01],\n",
      "        [-1.2314e-01],\n",
      "        [ 8.2893e-01],\n",
      "        [ 8.1940e-01],\n",
      "        [-2.7229e-01],\n",
      "        [-3.9976e-01],\n",
      "        [ 7.6426e-01],\n",
      "        [ 7.9184e-01],\n",
      "        [ 9.6917e-01],\n",
      "        [ 1.0460e+00],\n",
      "        [-1.8719e-01],\n",
      "        [ 1.4252e-01],\n",
      "        [ 1.2002e+00],\n",
      "        [-9.1400e-01],\n",
      "        [-1.3409e+00],\n",
      "        [ 1.0728e+00],\n",
      "        [ 3.3416e-01],\n",
      "        [-5.8307e-01],\n",
      "        [ 3.6559e-01],\n",
      "        [-3.3318e-01],\n",
      "        [-1.9900e-01],\n",
      "        [ 8.8738e-01],\n",
      "        [ 4.6421e-01],\n",
      "        [ 7.7522e-01],\n",
      "        [ 7.6691e-01],\n",
      "        [-4.5625e-01],\n",
      "        [-3.6650e-01],\n",
      "        [ 1.6017e+00],\n",
      "        [-2.5702e-01],\n",
      "        [-3.4317e-03],\n",
      "        [-4.0594e-01],\n",
      "        [ 4.1421e-01],\n",
      "        [-1.9418e-01],\n",
      "        [-3.6073e-01],\n",
      "        [-1.1216e-03],\n",
      "        [ 4.7687e-01],\n",
      "        [ 4.0086e-03],\n",
      "        [ 2.6708e-01],\n",
      "        [ 6.0145e-01],\n",
      "        [-1.4422e+00],\n",
      "        [ 4.1172e-01],\n",
      "        [-3.1492e-01],\n",
      "        [-5.8366e-03],\n",
      "        [ 3.6231e-01],\n",
      "        [ 1.0136e+00],\n",
      "        [-2.3385e-01],\n",
      "        [ 3.2971e-01],\n",
      "        [ 5.9877e-01],\n",
      "        [ 4.2408e-01],\n",
      "        [-5.4290e-01],\n",
      "        [ 4.8597e-01],\n",
      "        [ 3.7212e-01],\n",
      "        [ 6.7916e-01],\n",
      "        [-2.6530e-01],\n",
      "        [-1.1939e+00],\n",
      "        [ 2.2368e-01],\n",
      "        [-9.2474e-02],\n",
      "        [ 2.7125e-01],\n",
      "        [ 8.4953e-03],\n",
      "        [-4.1826e-01],\n",
      "        [-2.2853e-01],\n",
      "        [-8.9496e-01],\n",
      "        [ 6.2114e-01],\n",
      "        [-5.6603e-01],\n",
      "        [ 1.3157e-01],\n",
      "        [-2.9474e-01],\n",
      "        [-2.2945e-01],\n",
      "        [-2.0167e-01],\n",
      "        [-1.6623e-02],\n",
      "        [ 2.1198e-01],\n",
      "        [-3.2534e-01],\n",
      "        [ 7.4879e-01],\n",
      "        [-6.0278e-01],\n",
      "        [ 3.8763e-01],\n",
      "        [-4.6654e-01],\n",
      "        [ 7.5020e-01],\n",
      "        [ 2.6483e-01],\n",
      "        [-4.2787e-01],\n",
      "        [ 3.1347e-01],\n",
      "        [ 4.1749e-01],\n",
      "        [ 7.0773e-01],\n",
      "        [-2.6373e-02],\n",
      "        [-4.8906e-01],\n",
      "        [ 1.2623e+00],\n",
      "        [ 2.5306e-01],\n",
      "        [-7.4157e-01],\n",
      "        [-5.6427e-01],\n",
      "        [-2.4354e-01],\n",
      "        [ 6.6027e-01],\n",
      "        [ 2.7789e-01],\n",
      "        [ 5.7360e-01],\n",
      "        [ 7.0934e-01],\n",
      "        [-3.9598e-01],\n",
      "        [-3.9008e-01],\n",
      "        [-5.4236e-01],\n",
      "        [-5.1306e-01],\n",
      "        [-4.9243e-01],\n",
      "        [-6.3544e-01],\n",
      "        [-3.4180e-01],\n",
      "        [-6.5411e-01],\n",
      "        [-2.7016e-01],\n",
      "        [-8.6027e-01],\n",
      "        [ 2.7100e-01],\n",
      "        [ 6.0821e-02],\n",
      "        [-1.4788e-03],\n",
      "        [-4.2428e-01],\n",
      "        [ 1.2107e-02],\n",
      "        [ 4.1313e-01],\n",
      "        [ 1.3734e+00],\n",
      "        [-3.9517e-01],\n",
      "        [ 3.5714e-01],\n",
      "        [ 6.3914e-01],\n",
      "        [ 2.6082e-01],\n",
      "        [-8.0105e-02],\n",
      "        [ 3.8737e-01],\n",
      "        [ 4.3375e-01]])\n"
     ]
    }
   ],
   "source": [
    "############################################Intento 3####################################################\n",
    "subclass_model = SubclassModel(120)\n",
    "\n",
    "optimizer = optim.SGD(subclass_model.parameters(), lr=1e-2)\n",
    "training_loop(\n",
    "    n_epochs=5000,\n",
    "    optimizer=optimizer,\n",
    "    model=subclass_model,\n",
    "    loss_fn=nn.MSELoss(), # Ya no estamos usando nuestra loss function hecha a mano\n",
    "    train_x = train_t_un,\n",
    "    val_x = val_t_un,\n",
    "    train_y = train_t_c,\n",
    "    val_y = val_t_c)\n",
    "\n",
    "print('output', subclass_model(val_t_un))\n",
    "print('answer', val_t_c)\n",
    "print('hidden', subclass_model.hidden_linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7tmJULwbb1i6"
   },
   "outputs": [],
   "source": [
    "#################################### Respuesta 1##############################################################\n",
    "\n",
    "#Asi como se puede ver en el intento 1, el tener un learning rate mas pequeo hace que sea necesario aumenta el numero de epochs para que el loss se reduzca \n",
    "#En el intento 3 probamos que el loss se puede reducir aumentando el numero de epochs y aumentando el learning rate, pero esto tiende a un overfit de la data, por lo que decidir\n",
    "#cuidadosamente cuantos epochs tendra la funcion y el porcentaje de learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "7CoM9hYjdMsv",
    "outputId": "8c6da992-1a02-49e8-e8c8-eb8c762662bb"
   },
   "outputs": [],
   "source": [
    "#################################### Intento 4 ##############################################################\n",
    "import csv\n",
    "import csv\n",
    "with open('winequality-white.csv', 'r') as f:\n",
    "    wines = list(csv.reader(f, delimiter=';'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "sLbFXZiSj8-Z",
    "outputId": "28ed9cfc-7336-4462-9677-613897acd498"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-5f7b36335696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'winequality-white.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    622\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: winequality-white.csv not found."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea4_YuriKaffaty.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
